Measurement Protocol
====================

### Room

EPFL, ELA 006 Anechoic Chamber

### Date and Time

**Date** 2017 / 09 / 26

**Time Start** 12:19

**Time End** 19:46

### Team

Hanjie Pan, Robin Scheibler

### Summary

This experiment aims at collecting a dataset for the evaluation of direction
of arrival finding algorithms for both 2D and 3D algorithms.

The microphone array [pyramic](http://github.com/LCAV/pyramic) with 48 MEMS
microphones was placed on K&B turntable and rotated 360 degrees in increments
of 2 degrees for a total of 180 distinct angles. Three loudspeakers were placed
at fixed locations, all forming the same angle with the array, but with 3
different heights.

A total of 8 samples were played by each loudspeaker for each angle:

* Linear sweep, `samples/sweep_lin.wav`, 48 kHz
* Exponential sweep, `samples/sweep_exp.wav`, 48 kHz
* White noise, `samples/noise.wav`, 48 kHz
* 3 female speech samples, `samples/fq_sampleX.wav`, `X=0,1,3`, 16kHz
* 2 male speech samples, `samples/fq_sampleX.wav`, `X=2,4`, 16kHz

The sweeps were generated by running

    python ./code/gen_sweeps.py

The random noise sample was generated using the `numpy.random.randn` function.

The speech samples were picked from the TIMIT corpus as follows

* `fq_sample0` : FAKS0 / SA1 (female)
* `fq_sample1` : FCMR0 / SA2 (female)
* `fq_sample2` : MDLD0 / SX13 (male)
* `fq_sample3` : FMGD0 / SX34 (female)
* `fq_sample4` : MJLN0 / SX99 (male)

All the samples were resampled at 48 kHz if necessary and stitched into one
file (`all_samples.wav`) before playback.  The playback was done at 48 kHz.

### Experimental Data and Equipment

The file `protocol.json` contains both the environmental conditions (temperature
and humidity), the material used, and the geometry of the experiment (the
relative locations of microphones and loudspeakers).

### Code

The scripts used for automating the experiment are stored in the `code` folder.
Each script contains a short description of its purpose.

* `deconvolution.py` perform deconvolution in the frequency domain
* `gen_sweeps.py` generates a linear and an exponential sweep, as well as their time windowed versions
* `run_experiment.py` runs the full experiment
* `segment.py` segments the recorded files into separated files corresponding
  to each original sample. It resamples the recorded speech samples at 16 kHz.
* `stitch_samples.py` resample and stitch together all the samples and creates `all_samples.wav`

#### Dependencies

[Python 3.5.3](https://www.python.org/download/releases/3.0/) was used to run the
experiment. The following three standard modules are required and can be
installed via pip.

* [SoundDevice](https://github.com/spatialaudio/python-sounddevice)
* Numpy
* Scipy

In addition, these two custom modules should be downloaded. Edit `EASYDSP_PATH`
and `TURNTABLE_PATH` in `run_experiment.py` to indicate their locations.

* [Turntable Driver](https://github.com/LCAV/PyTurntableBK9640) `Commit: 27446ae17888e902a51f4867b59bd20064135fc7`
* [Easy DSP](https://github.com/LCAV/easy-dsp) `Commit: 16b4e807a8fe1d82caa81baf6345446fd6e655cb`


#### Identify Turntable device name

    >>> import visa
    >>> rm = visa.ResourceManager()
    >>> rm.list_resources()
    ('ASRL1::INSTR', 'ASRL2::INSTR', 'ASRL3::INSTR', 'ASRL4::INSTR', 'GPIB0::12::INSTR')

#### Run the experiment

The data was collected by running

    python code/run_experiment.py -a pyramic -r 0:360:2 -o 2 -t ASRL4::INSTR 192.168.0.101

where `-o 2` indicated the number of the playback device, `-t ASRL4::INSTR` the address of the turntable,
and `192.168.0.101` the IP address of the Pyramic array.

### Dataset

#### Download the dataset

The dataset can be downloaded in in wav format (raw recordings) which makes it
straightforward to read and process, but heavy to download (~50GB).
Alternatively, a losslessly compressed version is also distributed (~17GB).
Utilities to compress/uncompress are provided in the form of shell and python
scripts, relying on [FFMPEG](https://ffmpeg.org).

The `sha256` checksums of the wav files is available in `checksums.txt`. The checksums
were obtained by running

    sha256sum recordings/ > checksums.txt

and can be verified against the version downloaded (assuming the recordings wav files are in `recordings`)

    sha256sum -c checksums.txt

#### File Naming

The recording files are named according to the following pattern:

    recordings/pyramic_spkrX_all_samples_Y.wav

where `X` is the loudspeaker index and `Y` is the angle by which the array was
rotated in the trigonometric direction (i.e. _counterclockwise_).  __Note__:
Since the array rotates counterclockwise, the rotation of the loudspeaker
relative to the array is _clockwise_ (or negative trigonometric direction).

#### Compression

To reduce the file size efficiently, they were compressed using the [True
Audio](https://en.wikipedia.org/wiki/TTA_(codec)) (TTA) lossless compression format.
This format can compressed and uncompressed using [FFMPEG](https://ffmpeg.org).
Decompression of the files can be done using older versions of ffmpeg (e.g. 2.8),
but compression (normally not needed for using this data) a newer version like 3.3
is required.

The files were compressed by running

    ./code/compress.sh recordings compressed_recordings

and then wrapped in a tar archive by

    tar cfv compressed_recordings.tar compressed_recordings/

The files can be uncompressed to wav directly from the tar
archive by running

    python ./code/uncompress.py /path/to/compressed_archive.tar /path/to/output/dir

This command will read the TTA compressed file from the tar archive, uncompress
to wav and save them to the output directory.

Alternatively, the TTA files can be extracted from the tar archive (`tar xfv
compressed_recordings.tar`) and read directly from python (via ffmpeg)

    import sys
    sys.path.append('./code/')
    import ffmpeg_audio

    r,data = ffmpeg_audio.read('./compressed_recordings/pyramic_spkr0_all_samples_0.wav')

#### Segmentation

The script `code/segment.py` allows to perform the segmentation of all files in
parallel using `ipyparallel` module. Run the following.

    python code/segment.py -a -q -o <output_dir> recordings

The segmented files are saved in the `<output_dir>` folder following the naming convention

    <output_dir>/<sample_name>_spkrX_angleZ.wav
    
where this time `Z` is the relative angle the speaker forms with the array
(i.e. `360 - Y`). The option `-q` will create spectrogram pictures of all
segmented files for quick visual inspection of the result.

#### Impulse Responses

The response of every microphone to every angle was obtained from the linear
sweep by a deconvolution.

### Notes

* Bugs with the USB interface crashed the computer several times and the
  measurements were thus taken by batch. The batches are the following. 

  * Batch 1: Angles 0 to 14
  * Batch 2: 16 to 180
  * Batch 3: 182 to 190
  * Batch 4: 192 to 206 
  * Batch 5: 208 to 216
  * Batch 6: 218 to 358
  
* During quality control a glitch in recording at angle 310 with spkr 0 was
  found and the measurement was repeated on the next morning, but before the
  setup was moved. When the measurement was repeated, the temperature was 21.6C
  and the humidity 48.9%. The glitched sample is preserved in the 'discarded'
  directory."

